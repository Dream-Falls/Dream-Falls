{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8706766,"sourceType":"datasetVersion","datasetId":5222630}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import SimpleImputer, IterativeImputer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import BaggingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Load the datasets\nX = pd.read_csv(\"/kaggle/input/vaccine/training_set_features.csv\") # Load the training features\ny = pd.read_csv(\"/kaggle/input/vaccine/training_set_labels.csv\") # Load the training labels \nz = pd.read_csv(\"/kaggle/input/vaccine/training_set_labels.csv\") # Load the training labels (for another target variable)\nfinal = pd.read_csv(\"/kaggle/input/vaccine/test_set_features.csv\") # Load the test features\n\n# Remove respondent_id, employment_industry, employment_occupation and health_insurance from X \nX = X.drop(['respondent_id', 'employment_industry', 'employment_occupation', 'health_insurance'], axis=1)\n\n# Remove respondent_id, seasonal_vaccine from y\ny = y.drop(['respondent_id', 'seasonal_vaccine'], axis=1)\n\n# Remove respondent_id, h1n1_vaccine from z \nz= z.drop(['respondent_id', 'xyz_vaccine'], axis=1)\n\n# Extracting the respondent_id column from the final \nrespondent_id = final['respondent_id']\n\n# Remove respondent_id, employment_industry, employment_occupation and health_insurance from final dataframe\nfinal = final.drop(['respondent_id', 'employment_industry', 'employment_occupation', 'health_insurance'], axis=1)\n\n# Define numerical and categorical features\nnumerical_features = X.select_dtypes(include=['float64']).columns\ncategorical_features = X.select_dtypes(include=['object']).columns\n\n# Define numerical and categorical transformers\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', IterativeImputer(max_iter=12, tol=0.001, random_state=42)),\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine numerical and categorical transformers using ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Define stratified k-fold cross-validator\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Define hyperparameters found by stratified gridsearchcv and randomsearchcv\nxgb_params = {'n_estimators':100, 'max_depth':7,\n                              'min_child_weight':15, 'eta':0.07, 'reg_lambda':0.15,\n                              'random_state':42}\nbagging_params = {'n_estimators':50, 'random_state':42, \n                                      'max_samples':0.8,'max_features':0.9, 'bootstrap':True}\n\n# Define function to evaluate model\ndef evaluate_model(X_data, y_data):\n    \n    # Compute scale_pos_weight based on the class distribution in the training data\n    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n    \n    # Define the BaggingClassifier with XGBClassifier as the base estimator\n    model_xgb = XGBClassifier(objective='binary:logistic', scale_pos_weight=scale_pos_weight, **xgb_params)\n    model_bagging = BaggingClassifier(estimator=model_xgb, **bagging_params)\n\n    roc_auc_scores = []\n \n    # Perform stratified k-fold taining and testing\n    for train_index, test_index in skf.split(X_data, y_data):\n        X_train_skf, X_test_skf = X_data[train_index], X_data[test_index]\n        y_train_skf, y_test_skf = y_data[train_index], y_data[test_index]\n\n        # Fit the model\n        model_bagging.fit(X_train_skf, y_train_skf)\n\n        # Predict on the test set\n        y_pred_proba = model_bagging.predict_proba(X_test_skf)[:, 1]  # Probability of positive class\n        # Evaluate the model\n        roc_auc = roc_auc_score(y_test_skf, y_pred_proba, average=\"macro\")\n        roc_auc_scores.append(roc_auc)\n        \n    # Calculate mean roc_auc scores across all fold\n    mean_roc_auc = sum(roc_auc_scores) / len(roc_auc_scores)\n    \n    return mean_roc_auc\n\n# Preprocess X\nX_processed = preprocessor.fit_transform(X)\n\n# Evaluate model for h1n1_vaccine\nprint(\"Evaluation for xyz_vaccine :\")\nroc_auc_y = evaluate_model(X_processed, y.values.ravel())\nprint(\"Mean ROC AUC Score for xyz_vaccine =\", roc_auc_y)\n\n# Evaluate model for seasonal_vaccine\nprint(\"\\nEvaluation for seasonal_vaccine:\")\nroc_auc_z = evaluate_model(X_processed, z.values.ravel())\nprint(\"Mean ROC AUC Score for seasonal_vaccine =\", roc_auc_z)\n\n# Calculate final mean roc_auc score for both y and z\nfinal_mean_roc_auc = (roc_auc_y + roc_auc_z) / 2\nprint(\"\\nOverall ROC AUC Score =\", final_mean_roc_auc)\n\n# Transform final\nfinal_processed = preprocessor.transform(final)\n\n# Training each model with entire dataset to make predictions on given unseen data (final dataframe)\ndef predict(X_data, y_data):\n    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n    best_model = BaggingClassifier(estimator=XGBClassifier(objective='binary:logistic', scale_pos_weight=scale_pos_weight, **xgb_params), **bagging_params)\n    best_model.fit(X_data, y_data)\n    vaccine_probs = best_model.predict_proba(final_processed)[:, 1]\n    # Round the probabilities to one decimal place\n    vaccine = np.round(vaccine_probs, 1)\n    return vaccine\n\nh1n1_vaccine = predict(X_processed, y.values.ravel())\nseasonal_vaccine = predict(X_processed, z.values.ravel())\n\n# Create DataFrame for predictions\npredictions_df = pd.DataFrame({\n    'respondent_id': respondent_id,\n    'h1n1_vaccine': h1n1_vaccine,\n    'seasonal_vaccine': seasonal_vaccine\n})\n\n# Save results to CSV file\npredictions_df.to_csv(\"results.csv\", index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T18:30:10.766395Z","iopub.execute_input":"2024-06-16T18:30:10.766792Z","iopub.status.idle":"2024-06-16T18:38:49.516784Z","shell.execute_reply.started":"2024-06-16T18:30:10.766759Z","shell.execute_reply":"2024-06-16T18:38:49.515647Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Evaluation for xyz_vaccine :\nMean ROC AUC Score for xyz_vaccine = 0.8415850120005078\n\nEvaluation for seasonal_vaccine:\nMean ROC AUC Score for seasonal_vaccine = 0.8588153071611204\n\nOverall ROC AUC Score = 0.8502001595808142\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions_df.to_csv(\"/kaggle/working/results.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T18:38:49.689671Z","iopub.execute_input":"2024-06-16T18:38:49.690038Z","iopub.status.idle":"2024-06-16T18:38:49.745217Z","shell.execute_reply.started":"2024-06-16T18:38:49.690001Z","shell.execute_reply":"2024-06-16T18:38:49.744240Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}